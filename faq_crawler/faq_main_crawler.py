from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from webdriver_manager.chrome import ChromeDriverManager
import time
import csv

category_ids = [
    "kb-index__category-96270652585",
    "kb-index__category-96270652588",
    "kb-index__category-183209302874",
    "kb-index__category-109588216638",
    "kb-index__category-96270652591",
    "kb-index__category-99253856275",
    "kb-index__category-99517563170",
    "kb-index__category-124236221025",
    "kb-index__category-123975591959",
    "kb-index__category-180106123880",
    "kb-index__category-96273009811"
]

# ãƒ–ãƒ©ã‚¦ã‚¶è¨­å®š
options = Options()
options.add_argument('--headless')  
options.add_argument('--disable-gpu')
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

def scrape_category(driver, category_id, global_index, writer):
    print(f"\nğŸ‘‰ ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã«æˆ»ã‚Šã¾ã—ãŸã€‚æ¬¡ã¯ã“ã‚Œã‚’å‡¦ç†ã™ã‚‹ï¼š{category_id}")
    driver.get("https://knowledge.squadbeyond.com/")
    time.sleep(2)

    try:
        category = driver.find_element(By.CSS_SELECTOR, f'a#{category_id}')
        driver.execute_script("arguments[0].click();", category)
        print(f"âœ… ã‚¯ãƒªãƒƒã‚¯ã§ããŸï¼š{category_id}")
        time.sleep(2)
    except:
        print(f"âŒ category_idè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸï¼š {category_id}ã€ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹")
        return global_index

    # â€œã•ã‚‰ã«è¡¨ç¤ºâ€ 10å›ã¾ã§
    show_more_clicks = 0
    for _ in range(10):
        try:
            show_more = driver.find_element(By.XPATH, '//div[@class="content-container"]//a[contains(text(), "ã•ã‚‰ã«è¡¨ç¤º")]')
            show_more.click()
            show_more_clicks += 1
            print(f"ğŸ”„ ã‚¯ãƒªãƒƒã‚¯ã€ã•ã‚‰ã«è¡¨ç¤ºã€ ç¬¬ {show_more_clicks} å›")
            time.sleep(1)
        except:
            print("ğŸšª No moreã€ã•ã‚‰ã«è¡¨ç¤ºã€")
            break

    # ä»¶æ•°ã‚’æ¢ã™
    faq_items = driver.find_elements(By.XPATH, '//div[@class="kb-categories"]//li/a')
    print(f"ğŸ“‹ find {len(faq_items)} ä»¶ç›®")

    for item in faq_items:
        href = item.get_attribute('href')
        try:
            WebDriverWait(driver, 2).until(lambda d: item.text.strip() != "")
            text = item.text.strip()
        except:
            text = "[èª­ã¿è¾¼ã¿ã§ããªã‹ã£ãŸ]"
        writer.writerow([global_index, href, text])
        print(f"ğŸ“ {global_index}. {text} -> {href}")
        global_index += 1
    return global_index

# ä¸»æµç¨‹
try:
    with open("faq_result.csv", "w", newline='', encoding="utf-8") as f:
        writer = csv.writer(f, delimiter='\t')
        writer.writerow(["No", "URL", "Title"])
        index = 1
        for cat_id in category_ids:
            index = scrape_category(driver, cat_id, index, writer)
finally:
    driver.quit()
    print("\nğŸ ã§ããŸã‚ˆã€‚faq_result.csvã‚’ç¢ºèªã—ã¦ã­ã€‚")
